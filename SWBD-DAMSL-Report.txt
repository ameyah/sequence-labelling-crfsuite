Assignment 3 Report

Name: Ameya Hanamsagar
Email: ahanamsa@usc.edu

1. If you included files other than baseline_crf.py, advanced_crf.py, evaluate_model.py, and hw3_corpus_tool.py, or modified hw3_corpus_tool.py please describe what the files do and/or your modifications to hw3_corpus_tool.py.

    My submission contains no extra files other than baseline_crf.py, advanced_crf.py, evaluate_model.py, and hw3_corpus_tool.py
    However, I have modified the hw3_corpus_tool.py file so that get_data function returns "file name" along with
    utterances present in the .csv file for each file. This modification enables me to effectively store labels
    for each (dialogue) file and write them in the OUTPUT_FILE.

2. Describe how you evaluated your baseline and advanced features

    I separated the labeled data manually into ~75% and ~25% for training and testing respectively.
    The files were taken at random for testing. I didn't remove the act_tags. However, during tagging, I just didn't
    consider the act_tags and passed only the features to CRF tagger. The evaluate_model.py scans the OUTPUT FILE
    generated by the tagger and matches the labels with that of the actual act_tags in the test data, thus calculating
    the accuracy.

3. Describe your advanced feature set.

    I kept the 4 baseline features as it is:
    (referring from Assignment description)
        (1) a feature for whether or not the speaker has changed in comparison with the previous utterance.
        (2) a feature marking the first utterance of the dialogue.
        (3) a feature for every token in the utterance.
        (4) a feature for every part of speech tag in the utterance (e.g., POS_PRP POS_RB, POS_VBP POS_.).
    Additionally, I added the following features:
        (5) a feature marking the last utterance of the dialogue.
        (6) features for highlighting the first token and last token of an utterance.
        (7) a feature specifying the length of words/tokens in an utterance.
        (8) excluded tokens and POS tags that are "." or "," except when they are first or last tokens.
        (8) a feature for all bigram tokens in every utterance. For eg. if the tokens are: "and/CC we/PRP loved/VBD it/PRP ./.",
            the bigrams generated would be "TOKEN_and_TOKEN_we", "TOKEN_we_TOKEN_loved", "TOKEN_loved_TOKEN_it",
            "TOKEN_it_TOKEN_."
        (9) a feature for all bigram POS tags in every utterance. For eg. if the tokens are: "and/CC we/PRP loved/VBD it/PRP ./.",
            the bigrams generated would be "POS_CC_POS_PRP", "POS_PRP_POS_VBD", "POS_VBD_POS_PRP", "POS_PRP_POS_."
       (10) a feature specifying first token of the next utterance, except in the case where that token doesn't exist.
       (11) if any utterance doesn't have any tokens, then adding "TOKEN_NONE" and "POS_NONE" to the features of that
            utterance.

4. If you tried alternate advanced feature sets, please describe them.

    (1) Apart from the above features, I tried including trigrams (2 cases: bigrams included and not included) in the feature
        set (similar to including bigrams), the accuracy became slightly worse. So, I discarded them.
    (2) I also tried including 2 sets of bigrams: previous and current word, and current word and next word. However, again
        the accuracy was slightly worse.
    (3) I tried removing tokens that were in the stopwords list, but it didn't help

5. Accuracy of baseline features was: 0.7224271244828038
6. Accuracy of advanced features was: 0.7447812330331567